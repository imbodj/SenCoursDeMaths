\input{../common}
\input{../bibliography}

\begin{document}
  %<*content>
  \lesson{analysis}{219}{Extremums : existence, caractérisation, recherche. Exemples et applications.}

  \subsection{Existence et unicité}

  \reference[R-R]{210}

  \begin{definition}
    Soient $U$ un ouvert d'un espace vectoriel normé $E$ et $f : U \rightarrow \mathbb{R}$.
    \begin{itemize}
      \item On dit que $f$ admet un \textbf{maximum local} (resp. \textbf{minimum local}) en $a \in U$ si
      \[ \exists r > 0 \text{ tel } \forall x \in B(a,r), \, f(x) \leq f(a) \text{(resp. } f(x) \geq f(a) \text{)} \]
      \item On dit que $f$ admet un \textbf{extremum local} en $a \in U$ si elle admet un minimum ou un maximum local.
    \end{itemize}
  \end{definition}

  \subsubsection{Utilisation de la compacité}

  \reference[GOU20]{31}

  \begin{theorem}[Des bornes]
    Soient $E$ un espace compact et $f : E \rightarrow \mathbb{R}$ continue. Alors, il existe deux éléments $a$ et $b$ de $E$ vérifiant
    \[ f(a) = \inf_{x \in E} f(x) \text{ et } f(b) = \sup_{x \in E} f(x) \]
  \end{theorem}

  \reference[HAU]{202}

  \begin{cexample}
    La fonction
    \[
    \begin{array}{ccc}
      \mathbb{R} &\rightarrow& \mathbb{R} \\
      x &\mapsto& \begin{cases}
        \frac{(-1)^q (q-1)}{q} &\text{si } x \in \mathbb{Q} \setminus \{ 0 \} \text{ avec } \frac{p}{q} \text{ le représentant irréductible de } x \\
        0 &\text{sinon}
      \end{cases}
    \end{array}
    \]
    est minorée par $-1$, majorée par $1$, mais n'atteint ses bornes sur aucun intervalle d'intérieur non vide de $\mathbb{R}$.
  \end{cexample}

  \reference[GOU20]{33}

  \begin{corollary}
    Soient $(E, d)$ un espace métrique et $K_1$, $K_2$ deux compacts de $E$. Alors,
    \[ \exists (x_1, x_2) \in K_1 \times K_2 \text{ tel que } d(x_1, x_2) = \inf_{(x,y) \in K_1 \times K_2} d(x,y) \]
  \end{corollary}

  \reference[ROU]{171}

  \begin{corollary}[Point fixe dans un compact]
    Soit $(E,d)$ un espace métrique compact et $f : E \rightarrow E$ telle que
    \[ \forall x, y \in E, \, x \neq y \implies d(f(x), f(y)) < d(x,y) \]
    alors $f$ admet un unique point fixe et pour tout $x_0 \in E$, la suite des itérés
    \[ x_{n+1} = f(x_n) \]
    converge vers ce point fixe.
  \end{corollary}

  \begin{example}
    $\sin$ admet un unique point fixe sur $[0,1]$.
  \end{example}

  \reference[GOU20]{35}

  \begin{cexample}
    La fonction
    \[
    \begin{array}{ccc}
      \mathbb{R} &\rightarrow& \mathbb{R} \\
      x &\mapsto& \begin{cases}
        1 &\text{si } x < 0 \\
        x + \frac{1}{1+x} &\text{sinon}
      \end{cases}
    \end{array}
    \]
    est continue, contractante et sans point fixe.
  \end{cexample}

  \reference{31}

  \begin{corollary}[Théorème de Heine]
    Une application continue sur un compact y est uniformément continue.
  \end{corollary}

  \reference[DAN]{58}

  \begin{application}[Théorème de d'Alembert-Gauss]
    Tout polynôme non constant de $\mathbb{C}$ admet une racine dans $\mathbb{C}$.
  \end{application}

  \subsubsection{Utilisation de la convexité}

  \reference[ROM19-1]{234}

  Soit $I \subseteq \mathbb{R}$ un intervalle non réduit à un point.

  \begin{proposition}
    Une fonction $f : \mathbb{R} \rightarrow \mathbb{R}$ est constante si et seulement si elle est convexe et majorée.
  \end{proposition}

  \begin{cexample}
    La fonction $f$ définie sur $\mathbb{R}^+$ par $f(x) = \frac{1}{1+x}$ est convexe, majorée, mais non constante.
  \end{cexample}

  \begin{proposition}
    Si $f : I \rightarrow \mathbb{R}$ est convexe et est dérivable en un point $\alpha \in \mathring{I}$ tel que $f'(\alpha) = 0$, alors $f$ admet un minimum global en $\alpha$.
  \end{proposition}

  \begin{proposition}
    Si $f : I \rightarrow \mathbb{R}$ est convexe et admet un minimum local, alors ce minimum est global.
  \end{proposition}

  \subsubsection{Utilisation de l'holomorphie}

  \reference[QUE]{102}

  Soient $\Omega$ un ouvert connexe de $\mathbb{C}$ et $f : \Omega \rightarrow \mathbb{C}$.

  \begin{proposition}[Inégalités de Cauchy]
    On suppose $f$ holomorphe au voisinage du disque $\overline{D}(a,R)$. On note $c_n$ les coefficients du développement en série entière de $f$ en $a$. Alors,
    \[ \forall n \in \mathbb{N}, \, \forall r \in [0,R], \, \vert c_n \vert \leq \frac{M(r)}{r^n} \]
    où $M(r) = \sup_{\vert z-a \vert = r} \vert f(z) \vert$.
  \end{proposition}

  \begin{corollary}[Théorème de Liouville]
    On suppose $f$ holomorphe sur $\mathbb{C}$ tout entier. Si $f$ est bornée, alors $f$ est constante.
  \end{corollary}

  \reference{107}

  \begin{theorem}[Principe du maximum]
    On suppose $\Omega$ borné et $f$ holomorphe dans $\Omega$ et continue dans $\overline{\Omega}$. On note $M$ le $\sup$ de $f$ sur la frontière (compacte) de $\Omega$. Alors,
    \[ \forall z \in \Omega, \, \vert f(z) \vert \leq M \]
  \end{theorem}

  \subsubsection{Utilisation de propriétés hilbertiennes}

  \reference[LI]{32}

  Soit $H$ un espace de Hilbert de norme $\Vert . \Vert$ et on note $\langle ., . \rangle$ le produit scalaire associé.

  \begin{lemma}[Identité du parallélogramme]
    \[ \forall x, y \in H, \, \Vert x + y \Vert^2 + \Vert x - y \Vert^2 = 2(\Vert x \Vert^2 \Vert y \Vert^2) \]
    et cette identité caractérise les normes issues d'un produit scalaire.
  \end{lemma}

  \dev{projection-sur-un-convexe-ferme}

  \begin{theorem}[Projection sur un convexe fermé]
    Soit $C \subseteq H$ un convexe fermé non-vide. Alors :
    \[ \forall x \in H, \exists! y \in C \text{ tel que } d(x, C) = \inf_{z \in C} \Vert x - z \Vert = d(x, y) \]
    On peut donc noter $y = P_C(x)$, le \textbf{projeté orthogonal de $x$ sur $C$}. Il s'agit de l'unique point de $C$ vérifiant
    \[ \forall z \in C, \, \langle x - P_C(x), z - P_C(x) \rangle \leq 0 \]
  \end{theorem}

  \begin{theorem}
    Si $F$ est un sous espace vectoriel fermé dans $H$, alors $P_F$ est une application linéaire continue. De plus, pour tout $x \in H$, $P_F(x)$ est l'unique point $y \in F$ tel que $x-y \in F^\perp$.
  \end{theorem}

  \begin{application}
    Soit $F$ un sous-espace vectoriel de $H$. Alors,
    \[ \overline{F} = H \iff F^\perp = 0 \]
  \end{application}

  \begin{application}[Théorème de représentation de Riesz]
    \[ \forall \varphi \in H', \, \exists! y \in H, \text{ tel que } \forall x \in H, \, \varphi(x) = \langle x, y \rangle \]
    et de plus, $\VERT \varphi \VERT = \Vert y \Vert$.
  \end{application}

  \begin{corollary}
    \[ \forall T \in H', \, \exists! U \in H' \text{ tel que } \forall x, y \in H, \, \langle T(x), y \rangle = \langle x, U(y) \rangle \]
    On note alors $U = T^*$ : c'est \textbf{l'adjoint} de $T$. On a alors $\VERT T \VERT = \VERT T^* \VERT$.
  \end{corollary}

  \reference[I-P]{336}

  \begin{application}
    Soit $J : H \rightarrow \mathbb{R}$ une fonction convexe, continue et vérifiant
    %\[ \forall M \in \mathbb{R}, \, \exists r > 0 \text{ tel que } \forall x \in H \text{ de norme } \geq r, \, f(x) \geq M \]
    \[ \forall (x_k) \in H^{\mathbb{N}} \text{ telle que } \Vert x_k \Vert \longrightarrow_{k \rightarrow +\infty} +\infty \text{ alors } J(x_k) \longrightarrow_{k \rightarrow +\infty} +\infty \]
    Alors, il existe $a \in H$ tel que
    \[ J(a) = \inf_{h \in H} J(h) \]
  \end{application}

  \subsection{Extrema et calcul différentiel}

  Soit $f : U \rightarrow \mathbb{R}$ différentiable en un point $a$ de $U$, où $U$ est un ouvert de $\mathbb{R}^n$.

  \subsubsection{Condition du premier ordre}

  \reference[R-R]{210}

  \begin{definition}
    Si $\mathrm{d}f_a = 0$, on dit que $a$ est un \textbf{point critique} de $f$.
  \end{definition}

  \begin{remark}
    Cela revient à dire que toutes les dérivées partielles de $f$ s'annulent en $a$.
  \end{remark}

  \begin{proposition}
    Si $f$ admet un extremum local en $a$, alors $a$ est un point critique de $f$.
  \end{proposition}

  \reference[HAU]{281}

  \begin{cexample}
    $(x,y) \mapsto x^2-y^2$ a un point critique en $(0,0)$, mais n'a pas d'extremum en $(0,0)$.
  \end{cexample}

  \subsubsection{Condition du second ordre}

  \reference[GOU20]{336}

  On suppose $f$ de classe $\mathcal{C}^2$ sur $U$.

  \begin{definition}
    La matrice \textbf{hessienne} de $f$ en $a$, notée $\operatorname{Hess}(f)_a$, est définie par
    \[ \operatorname{Hess}(f)_a = \left( \frac{\partial^2 f}{\partial x_i \partial x_j} \right)_{i,j \in \llbracket 1, n \rrbracket} \]
  \end{definition}

  \begin{remark}
    Pour $f$ de classe $\mathcal{C}^2$, $\operatorname{Hess}(f)_a$ est symétrique.
  \end{remark}

  \begin{theorem}
    On suppose $\mathrm{d}f_a = 0$. Alors :
    \begin{enumerate}[label=(\roman*)]
      \item Si $f$ admet un minimum (resp. maximum) relatif en $a$, $\operatorname{Hess}(f)_a$ est positive (resp. négative).
      \item Si $\operatorname{Hess}(f)_a$ définit une forme quadratique définie positive (resp. définie négative), $f$ admet un minimum (resp. maximum) relatif en $a$.
    \end{enumerate}
  \end{theorem}

  \begin{example}
    On suppose $\mathrm{d}f_a = 0$. On pose $(r,s,t) = \left(  \frac{\partial^2}{\partial x_i \partial x_j} f \right)_{i+j=2}$. Alors :
    \begin{enumerate}[label=(\roman*)]
      \item Si $rt-s^2 > 0$ et $r > 0$ (resp. $r < 0$), $f$ admet une minimum (resp. maximum) relatif en $a$.
      \item Si $rt-s^2 < 0$, $f$ n'a pas d'extremum en $a$.
      \item Si $rt-s^2 = 0$, on ne peut rien conclure.
    \end{enumerate}
  \end{example}

  \begin{example}
    La fonction $(x,y) \mapsto x^4 + y^2 - 2(x-y)^2$ a trois points critiques qui sont des minimum locaux : $(0,0)$, $(\sqrt{2},-\sqrt{2})$ et $(-\sqrt{2},\sqrt{2})$.
  \end{example}

  \begin{cexample}
    $x \mapsto x^3$ a sa hessienne positive en $0$, mais n'a pas d'extremum en $0$.
  \end{cexample}

  \subsubsection{Extrema liés}

  \reference{337}

  \begin{theorem}[Extrema liés]
    \label{219-1}
    Soient $f, g_1, \dots, g_r : U \rightarrow \mathbb{R}$ des fonctions de classe $\mathcal{C}^1$. On note $\Gamma = \{ x \in U \mid g_1(x) = \dots = g_r(x) = 0 \}$. Si $f_{|\Gamma}$ admet un extremum relatif en $a \in \Gamma$ et si les formes linéaires $\mathrm{d}(g_1)_a, \dots, \mathrm{d}(g_r)_a$ sont linéairement indépendantes, alors il existe des uniques $\lambda_1, \dots, \lambda_r$ tels que
    \[ \mathrm{d}f_a = \lambda_1 \mathrm{d}(g_1)_a + \dots + \lambda_r \mathrm{d}(g_r)_a \]
  \end{theorem}

  \begin{definition}
    Les $\lambda_1, \dots, \lambda_r$ du théorème précédent sont appelés appelés \textbf{multiplicateurs de Lagrange}.
  \end{definition}

  \reference[BMP]{21}

  \begin{remark}
    La relation finale du \cref{219-1} équivaut à
    \[ \bigcap_{i=1}^n \ker(\mathrm{d}(g_i)_a) \subseteq \ker(\mathrm{d}f_a) \]
    et elle exprime que $\mathrm{d}f_a$ est nulle sur l'espace tangent à $\Gamma$ en $a$ (ie. $\nabla f_a$ est orthogonal à l'espace tangent à $\Gamma$ en $a$).
  \end{remark}

  \begin{cexample}
    On pose $g : (x,y) \mapsto x^3-y^2$ et on considère $f : (x, y) \mapsto x+y^2$. On cherche à minimiser $f$ sous la contrainte $g(x,y) = 0$.
    \newpar
    Alors, le minimum (global) de $f$ sous cette contrainte est atteint en $(0,0)$, la différentielle de $g$ en $(0,0)$ est nulle et la relation finale du \cref{219-1} n'est pas vraie.
  \end{cexample}

  \begin{application}[Théorème spectral]
    Tout endomorphisme symétrique d'un espace euclidien se diagonalise dans une base orthonormée.
  \end{application}

  \reference{35}

  \begin{application}
    \[ \mathrm{SO}_n(\mathbb{R}) = \left\{ M \in \mathcal{M}_n(\mathbb{R}) \mid \Vert M \Vert^2 = \inf_{P \in \mathrm{SL}_n(\mathbb{R})} \Vert P \Vert^2 \right\} \]
    où $\Vert . \Vert : M \mapsto \sqrt{\trace(\tr{M}M)}$ (ie. $\mathrm{SO}_n(\mathbb{R})$ est l'ensemble des matrices de $\mathrm{SL}_n(\mathbb{R})$ qui minimisent la norme euclidienne canonique de $\mathcal{M}_n(\mathbb{R})$).
  \end{application}

  \reference[GOU20]{339}

  \begin{application}[Inégalité arithmético-géométrique]
    \[ \forall (x_1, \dots, x_n) \in (\mathbb{R}^+)^n, \, \left( \prod_{i=1}^{n} x_i \right)^{\frac{1}{n}} \leq \frac{1}{n} \sum_{i=1}^n x_i \]
  \end{application}

  \reference[ROU]{409}

  \begin{application}[Inégalité d'Hadamard]
    \[ \forall (x_1, \dots, x_n) \in \mathbb{R}^n, \, \det(x_1, \dots, x_n) \leq \Vert x_1 \Vert \dots \Vert x_n \Vert \]
    avec égalité si et seulement si $(x_1, \dots, x_n)$ est une base orthogonale de $\mathbb{R}^n$.
  \end{application}

  \subsection{Algorithmes d'optimisation numérique}

  \subsubsection{Méthode de Newton}

  \reference[ROU]{152}
  \dev{methode-de-newton}

  \begin{theorem}[Méthode de Newton]
    Soit $f : [c, d] \rightarrow \mathbb{R}$ une fonction de classe $\mathcal{C}^2$ strictement croissante sur $[c, d]$. On considère la fonction
    \[ \varphi :
    \begin{array}{ccc}
      [c, d] &\rightarrow& \mathbb{R} \\
      x &\mapsto& x - \frac{f(x)}{f'(x)}
    \end{array}
    \]
    (qui est bien définie car $f' > 0$). Alors :
    \begin{enumerate}[label=(\roman*)]
      \item $\exists! a \in [c, d]$ tel que $f(a) = 0$.
      \item $\exists \alpha > 0$ tel que $I = [a - \alpha, a + \alpha]$ est stable par $\varphi$.
      \item La suite $(x_n)$ des itérés (définie par récurrence par $x_{n+1} = \varphi(x_n)$ pour tout $n \geq 0$) converge quadratiquement vers $a$ pour tout $x_0 \in I$.
    \end{enumerate}
  \end{theorem}

  \begin{corollary}
    En reprenant les hypothèses et notations du théorème précédent, et en supposant de plus $f$ strictement convexe sur $[c, d]$, le résultat du théorème est vrai sur $I = [a, d]$. De plus :
    \begin{enumerate}[label=(\roman*)]
      \item $(x_n)$ est strictement décroissante (ou constante).
      \item $x_{n+1} - a \sim \frac{f''(a)}{2f'(a)} (x_n - a)^2$ pour $x_0 > a$.
    \end{enumerate}
  \end{corollary}

  \begin{example}
    \begin{itemize}
      \item On fixe $y > 0$. En itérant la fonction $F : x \mapsto \frac{1}{2} \left( x + \frac{y}{x} \right)$ pour un nombre de départ compris entre $c$ et $d$ où $0 < c < d$ et $c^2 < 0 < d^2$, on peut obtenir une approximation du nombre $\sqrt{y}$.
      \item En itérant la fonction $F : x \mapsto \frac{x^2+1}{2x-1}$ pour un nombre de départ supérieur à $2$, on peut obtenir une approximation du nombre d'or $\varphi = \frac{1+\sqrt{5}}{2}$.
    \end{itemize}
  \end{example}

  \subsubsection{Lien avec les systèmes linéaires}

  \reference[BMP]{24}

  \begin{proposition}
    Soient $A \in \mathcal{S}_n^{++}(\mathbb{R})$ et $b \in \mathbb{R}^n$. On pose $f : x \mapsto \frac{1}{2} \langle Ax, x \rangle + \langle b, x \rangle$. Alors, minimiser $f$ sur $\mathbb{R}^n$ revient à résoudre le système linéaire $Ax=b$.
  \end{proposition}
  %</content>
\end{document}
