\input{../common}
\input{../bibliography}

\begin{document}
  %<*content>
  \lesson{analysis}{221}{Équations différentielles linéaires. Systèmes d'équations différentielles linéaires. Exemples et applications.}

  Dans toute la suite, $\mathbb{K}$ désignera le corps $\mathbb{R}$ ou $\mathbb{C}$.

  \subsection{Généralités}

  \subsubsection{Définitions}

  \reference[GOU20]{373}

  \begin{definition}
    Soient $n \in \mathbb{N}^*$, $E$ un espace de Banach et $\Omega \subseteq \mathbb{R} \times E^n$ un ouvert. Soit $F : \Omega \times \mathbb{R}^n \rightarrow E$ une fonction.
    \begin{itemize}
      \item On appelle \textbf{équation différentielle} une équation de la forme
      \[ y^{(n)} = F(t, y, y', \dots, y^{(n-1)}) \tag{$*$} \]
      (ie. une équation portant sur les dérivées d'une fonction.)
      \item Toute application $\varphi : I \rightarrow E$ (où $I$ est un intervalle de $\mathbb{R}$) $n$ fois dérivable vérifiant :
      \begin{enumerate}[label=(\roman*)]
        \item $\forall t \in I, \, (t, \varphi(t), \dots, \varphi^{(n-1)}(t)) \in \Omega$ ;
        \item $\forall t \in I, \, F(t, \varphi(t), \dots, \varphi^{(n-1)}(t)) = \varphi^{(n)}(t)$ ;
      \end{enumerate}
      est une \textbf{solution} de $(*)$. On note $\mathcal{S}_*$ l'ensemble des solutions de $(*)$.
      \item Une solution $\varphi : I \rightarrow E$ de $(*)$ est dite \textbf{maximale} s'il n'existe pas d'autre solution $\psi : J \rightarrow E$ (où $J$ est un intervalle de $\mathbb{R}$) de $(*)$ telle que $I \subseteq J$, $I \neq J$ et $\psi = \varphi$ sir $I$.
      \item On appelle \textbf{problème de Cauchy} de $(*)$ en $(t_0, x_0, \dots, x_{n-1})$ la recherche d'une solution $\varphi : I \rightarrow E$ de $(*)$ vérifiant
      \[ \forall t_0 \in I, \, \varphi(t_0) = x_0, \dots, \varphi^{(n-1)}(t_0) = x_{n-1} \]
    \end{itemize}
  \end{definition}

  \reference{377}

  \begin{definition}
    Toute équation différentielle sur $\mathbb{K}^n$ d'ordre $p \geq 1$ du type
    \[ Y^{(p)} = A_{p-1}(t) Y^{(p-1)} + \dots + A_0(t) Y + B(t) \tag{$L$} \]
    (où $A_{p-1}, \dots, A_0$ sont des fonctions continues d'un intervalle $I$ de $\mathbb{R}$ non réduit à un point dans $\mathcal{M}_n(\mathbb{K})$ et $B : I \rightarrow \mathbb{K}^n$ est une fonction continue) est appelée \textbf{équation différentielle linéaire} d'ordre $p$.
    \newpar
    Si de plus $B = 0$, alors $(L)$ est qualifiée d'\textbf{homogène}.
  \end{definition}

  \begin{definition}
    Si $n \geq 2$, on parle de \textbf{système différentiel linéaire}. Si $n = 1$, on parle d'équation différentielle linéaire \textbf{scalaire}.
  \end{definition}

  \begin{remark}
    L'équation $(L)$ précédente peut aussi s'écrire :
    \[ \begin{pmatrix} Y \\ Y' \\ \vdots \\ \vdots \\ Y^{(p-1)} \end{pmatrix}' = \begin{pmatrix} 0 & I_n & 0 & \dots & 0 \\ \vdots & \ddots & \ddots & \ddots & \vdots \\ \vdots &  & \ddots & \ddots & 0 \\ 0 & \dots & \dots & 0 & I_n \\ A_0(t) & \dots & \dots & \dots & A_{p-1}(t) \end{pmatrix} \begin{pmatrix} Y \\ Y' \\ \vdots \\ \vdots \\ Y^{(p-1)} \end{pmatrix} + \begin{pmatrix} 0 \\ 0 \\ \vdots \\ \vdots \\ B(t) \end{pmatrix} \]
    Ainsi, nous avons ramené l'équation différentielle linéaire $(L)$ d'ordre $p$ à une équation différentielle linéaire d'ordre $1$. Donc, pour cette raison, on peut se limiter à l'étude des équations différentielles linéaires d'ordre $1$.
  \end{remark}

  \subsubsection{Structure de l'ensemble des solutions}

  \reference[DAN]{520}
  \dev{theoreme-de-cauchy-lipschitz-lineaire}

  \begin{theorem}[Cauchy-Lipschitz linéaire]
    Soient $A : I \rightarrow \mathcal{M}_n(\mathbb{K})$ et $B : I \rightarrow \mathbb{K}^d$ deux fonctions continues. Alors $\forall t_0 \in I$, le problème de Cauchy
    \[ \begin{cases} Y' = A(t)Y + B(t) \\ Y(t_0) = y_0 \end{cases} \]
    admet une unique solution définie sur $I$ tout entier.
  \end{theorem}

  \reference[GOU20]{378}

  \begin{remark}[Version linéaire d'ordre $p$]
    Soient $A_{p-1}, \dots, A_0$ des fonctions continues d'un intervalle $I$ de $\mathbb{R}$ non réduit à un point dans $\mathcal{M}_n(\mathbb{K})$ et $B : I \rightarrow \mathbb{K}^n$ une fonction continue. Soient $X_0, \dots, X_{p-1} \in \mathbb{K}^n$. Alors, $\forall t_0 \in I$, le problème de Cauchy
    \[ \begin{cases} Y^{(p)} = A_{p-1}(t) Y^{(p-1)} + \dots + A_0(t) Y + B(t) & \\ Y^{(k)}(t_0) = X_k & \forall k \in \llbracket 1, p-1 \rrbracket \end{cases} \]
    admet une unique solution définie sur $I$ tout entier.
  \end{remark}

  \reference[ROM19-1]{402}

  \begin{example}
    Considérons l'équation $y' - y = 0$. Comme la fonction nulle est solution maximale, il s'agit de l'unique solution qui s'annule sur $\mathbb{R}$.
  \end{example}

  \reference[GOU20]{278}

  \begin{corollary}
    L'ensemble des solutions d'une équation différentielle linéaire homogène d'ordre $p$ défini sur un intervalle $I$ est un sous-espace vectoriel de $\mathcal{C}^1 (I, \mathbb{K}^n)$ de dimension $np$.
  \end{corollary}

  \begin{corollary}
    Soit $(H)$ l'équation différentielle linéaire homogène associée à une équation différentielle linéaire $(L)$ et soit $V_0 \in \mathcal{S}_L$. Alors $\mathcal{S}_L = V_0 + \mathcal{S}_H$, et $\mathcal{S}_L$ est un espace affine de même dimension que $\mathcal{S}_H$.
  \end{corollary}

  \subsubsection{Wronskien}

  \begin{definition}
    Soient $V_1, \dots, V_n$ $n$ solutions d'une équation différentielle linéaire homogène $(H)$ définies sur un intervalle $I$. On appelle \textbf{wronskien} de $V_1, \dots, V_n$ l'application
    \[
    W_{(V_1, \dots, V_n)} :
    \begin{array}{ccc}
      I &\rightarrow& \mathbb{K} \\
      t &\mapsto& \det(V_1(t), \dots, V_n(t))
    \end{array}
    \]
  \end{definition}

  \begin{example}
    Soient $v_1, \dots, v_p$ $p$ solutions de $y^{(p)} = a_{p-1}(t)y^{(p-1)} + \dots + a_0(t) y$ définies sur un intervalle $I$ (où $\forall i, \, a_i : I \rightarrow \mathbb{K}$ est continue). Alors \[ \forall t \in I, \, W_{(v_1, \dots, v_p)}(t) = \begin{vmatrix} v_1(t) & \dots & v_p(t) \\ \vdots & & \vdots \\ v_1^{(p-1)}(t) & \dots & v_p^{(p-1)}(t) \end{vmatrix} \]
  \end{example}

  \begin{example}
    Soient $u$ et $v$ deux solutions de $y'' = a(t)y' + b(t)y$ définies sur un intervalle $I$. Alors \[ \forall t \in I, \, W_{(u, v)}(t) = u(t)v'(t) - u'(t)v(t) \]
  \end{example}

  \begin{proposition}
    Le rang de $n$ solutions d'une équation différentielle linéaire homogène $V_1(t), \dots, V_n(t)$ est indépendant de $t$.
  \end{proposition}

  \begin{corollary}
    Soient $V_1, \dots, V_n$ $n$ solutions d'une équation différentielle linéaire homogène $(H)$. Alors $(V_1, \dots, V_n)$ est une base de $\mathcal{S}_H$ si et seulement si $\exists t_0$ tel que $W_{(V_1, \dots, V_n)}(t_0) \neq 0$.
  \end{corollary}

  \reference{388}

  \begin{proposition}
    Soient $V_1, \dots, V_n$ $n$ solutions d'une équation différentielle linéaire homogène $(H)$. Alors $W_{(V_1, \dots, V_n)}$ est solution de l'équation différentielle linéaire homogène
    \[ Y' = \trace(A) Y \]
    et pour tout $t_0$ élément de $I$, on a $\forall t \in I, \, W_{(V_1, \dots, V_n)}(t) = W_{(V_1, \dots, V_n)}(t_0) \exp(\int_{t_0}^t \trace(A(u)) \, \mathrm{d}u)$.
  \end{proposition}

  \subsection{Résolution}

  \subsubsection{Cas d'une équation différentielle linéaire scalaire}

  \reference{379}

  \begin{proposition}
    Les solutions d'une équation différentielle linéaire homogène scalaire $y' = a(t) y$ sont proportionnelles à $t \mapsto e^{A(t)}$ où $A$ est une primitive de $a$.
  \end{proposition}

  \begin{corollary}[Variation de la constante]
    Soient $(L) : y' = a(t) y + b(t)$ une équation différentielle linéaire scalaire et $A$ une primitive de $a$. Alors,
    \[ \mathcal{S}_L = \left\{t \mapsto \lambda(t) e^{A(t)} \mid \lambda'(t) = b(t)e^{-A(t)}\right\} \]
  \end{corollary}

  \begin{example}
    L'ensemble des solutions de l'équation différentielle $(L) : y' + y = \sin(t)$ est
    \[ \mathcal{S}_L = \left \{ t \mapsto \frac{\sin(t) - \cos(t)}{2} + \mu e^{-t} \, \big\lvert \, \mu \in \mathbb{R} \right \} \]
  \end{example}

  \begin{example}
    À cause du principe de ``recollement'' des solutions, la seule solution définie sur $\mathbb{R}$ de $(1-t^2)y' + ty = 0$ est la fonction nulle.
  \end{example}

  \subsubsection{Cas d'un système différentiel linéaire}

  \begin{proposition}
    Soient $V_1, \dots, V_n$ $n$ solutions linéairement indépendantes d'une équation différentielle linéaire homogène $(H) : Y' = A(t) Y$. Alors,
    \[ \mathcal{S}_H = \left\{\sum_{i=1}^n \lambda_i V_i \mid \lambda_i \in \mathbb{K} \right\} \]
  \end{proposition}

  \begin{corollary}[Variation de la constante]
    Soit $(L) : Y' = A(t) Y + B(t)$ une équation différentielle linéaire. On note par $(H)$ le équation différentielle linéaire homogène associée. Alors, si $V_1, \dots, V_n$ sont $n$ solutions de $(H)$, on a :
    \[ \mathcal{S}_L = \left\{\sum_{i=1}^n \lambda_i(t) V_i \mid \sum_{i=1}^n \lambda_i'(t) V_i(t) = B(t)\right\} \]
  \end{corollary}

  \begin{example}
    Soit $(L) : y'' = a(t) y' + b(t)y + c(t)$. On note $u$ et $v$ deux solutions de l'équation différentielle linéaire homogène associée. Alors,
    \[ \mathcal{S}_L = \left\{t \mapsto \lambda(t) u(t) + \mu(t) v(t) \mid \begin{cases} \lambda'u + \mu'v = 0 \\ \lambda' u' + \mu' v' = c \end{cases} \right\} \]
  \end{example}

  \begin{example}
    On considère l'équation différentielle $(L) : y'' + y = \tan(t)$. Alors,
    \[ \mathcal{S}_L = \left\{t \mapsto \alpha \cos(t) + \beta \sin(t) - \cos(t) \ln \left( \tan \left( \frac{\pi}{4} + \frac{t}{2} \right) \right) \mid \alpha, \, \beta \in \mathbb{R} \right\} \]
  \end{example}

  \subsubsection{Cas où les coefficients sont constants}

  \begin{definition}
    Soit $A \in \mathcal{M}_n(\mathbb{K})$. On définit
    \[ e^{A} = \exp(A) = \sum_{k=0}^{+\infty} \frac{A^k}{k!} \]
    l'\textbf{exponentielle} de la matrice $A$.
  \end{definition}

  \begin{proposition}
    Une équation différentielle linéaire homogène $(H) : Y' = AY$ (où $A \in \mathcal{M}_n(\mathbb{R})$ est constante en $t$) a ses solutions maximales définies sur $\mathbb{R}$ et le problème de Cauchy
    \[ \begin{cases} Y' = AY \\ Y(0) = y_0 \end{cases} \]
    a pour (unique) solution $t \mapsto e^{tA} y_0$.
  \end{proposition}

  \begin{remark}
    En reprenant les notations précédentes, si $\mathbb{K} = \mathbb{R}$, on peut réduire $A$ dans $\mathbb{C}$ puis écrire les solutions de $(H)$ sous la forme $\varphi(t) + \overline{\varphi(t)}$ (où $\varphi$ est une solution complexe de $(H)$).
  \end{remark}

  \begin{corollary}
    On considère une équation différentielle linéaire homogène $(H) : y^{(n)} + a_{n-1} y^{(n-1)} + \dots + a_0 y = 0$. On factorise $P_H$, le \textbf{polynôme caractéristique} de l'équation dans $\mathbb{C}$,
    \[ P_H = X^n + a_{n-1}X^{n-1} + \dots + a_0 = \prod_{i=1}^k (X-r_i)^{m_i} \]
    Alors,
    \[ \mathcal{S}_H = \left\{t \mapsto \sum_{i=1}^k e^{r_i t} P_i(t)\right\} \]
    où les $P_i$ sont des polynômes de degré $< m_i$.
  \end{corollary}

  \begin{example}
    On considère l'équation différentielle $(H) : y'' + ay' + by = 0$. Soient $r_1$ et $r_2$ les deux racines de $P_H$ dans $\mathbb{C}$.
    \begin{itemize}
      \item Si $r_1 \neq r_2$, $\mathcal{S}_H = \{t \mapsto \lambda e^{r_1 t} + \mu e^{r_2 t} \mid \lambda, \mu \in \mathbb{C}\}$.
      \item Si $r_1 = r_2$, $\mathcal{S}_H = \{t \mapsto (\lambda t + \mu) e^{r t} \mid \lambda, \mu \in K\}$.
    \end{itemize}
  \end{example}

  \subsubsection{Quelques autres techniques de résolution}

  \paragraph{Abaissement de l'ordre}

  \begin{proposition}
    On considère une équation différentielle linéaire homogène $(H) : y^{(n)} = a_{n-1}(t) y^{(n-1)} + \dots + a_0(t) y$. Soit $\varphi \in \mathcal{S}_H$, alors $f = g \varphi$ est solution de $(H)$ si et seulement si
    \[ \sum_{k=1}^n \binom{n}{k} g^{k} \varphi^{(n-k)} = a_{n-1}(t) \sum_{k=1}^{n-1} \binom{n-1}{k} g^{k} \varphi^{(n-1-k)} + \dots + a_1(t) (g' \varphi) \]
    ie. $g'$ est solution d'une équation différentielle d'ordre $n-1$.
  \end{proposition}

  \begin{example}
    Soit $\varphi$ une solution de $(H) : y'' = a(t) y' + b(t) y$, alors $f = g \varphi$ est solution de $(H)$ si et seulement si $2g' \varphi' + g'' \varphi = a(t)g'\varphi$.
  \end{example}

  \paragraph{Utilisation des séries entières}

  \reference[ROM19-1]{401}

  \begin{proposition}
    Soient $a_0, \dots, a_{p-1}$ et $b$ des fonctions à valeurs dans $\mathbb{K}$ développables en série entière sur un intervalle ouvert $]-R, R[$ ($R$ étant un réel strictement positif). Soient $y_0, \dots, y_{p-1} \in \mathbb{C}$. On considère le problème de Cauchy :
    \[ \begin{cases} y^{(p)} = a_0(t)y + \dots + a_{p-1}(t)y^{(p-1)} + b(t) & \\ y^{(k)}(0) = y_k & \forall k \in \llbracket 0, p-1 \rrbracket \end{cases} \tag{$*$} \]
    Alors $(*)$ admet une unique solution développable en série entière sur $]-R,R[$.
  \end{proposition}

  \begin{example}
    La fonction $\sin : \mathbb{R} \rightarrow [1,1]$ est l'unique solution du problème de Cauchy
    \[ \begin{cases} y'' = y \\ y(0) = 0 \\ y'(0) = 1 \end{cases} \]
  \end{example}

  \reference{412}

  \begin{application}
    La fonction $f_\alpha : x \mapsto (1 + x)^\alpha$ où $\alpha \in \mathbb{R} \setminus \mathbb{N}$ est développable en série entière de rayon de convergence $1$ et
    \[ \forall x \in ]-1,1[, \, f_\alpha(x) = 1 + \sum_{n=1}^{+\infty} \frac{\alpha (\alpha - 1) \dots (\alpha - n+1)}{n!} x^n \]
  \end{application}

  \subsection{Études qualitatives}

  \reference[GOU20]{397}

  \begin{lemma}[Grönwall]
    Soient $\varphi, \psi, y : [a,b] \rightarrow \mathbb{R}^+$ continues vérifiant $\forall t \in [a,b], \, y(t) \leq \varphi(t) \left | \int_a^t \psi(s) y(s) \, \mathrm{d}s \right |$. Alors,
    \[ \forall t \in I, \, y(t) \leq \varphi(t) + \int_a^t \varphi(s) \psi(s) \exp \left( \int_s^t \psi(u) \, \mathrm{d}u \right) \, \mathrm{d}s \]
  \end{lemma}

  \begin{corollary}
    Soient $\varphi, y : [a,b] \rightarrow \mathbb{R}^+$  continues et vérifiant $\exists c \geq 0, \, \forall t \in [a, b], \, y(t) \leq c + \int_a^t \varphi(s) y(s) \, \mathrm{d}s$. Alors,
    \[ \forall t \in [a,b], \, y(t) \leq c \exp \left( \int_a^t \varphi(s) \, \mathrm{d}s \right) \]
  \end{corollary}

  \begin{application}
    Soit $q : \mathbb{R}^+ \rightarrow \mathbb{R}^+_*$ croissante de classe $\mathcal{C}^1$. Alors les solutions de $y'' + q(t) y = 0$ sont bornées sur $\mathbb{R}^+$.
  \end{application}

  \reference{387}

  \begin{theorem}[Floquet]
    On considère l'équation $(H) : Y' = A(t) Y$ où $A : \mathbb{R} \rightarrow \mathbb{C}$ est une fonction continue et $T$-périodique. Alors, $(H)$ admet une solution $V$ non nulle telle que
    \[ \exists \lambda \in \mathbb{C}, \forall t \in \mathbb{R}, \, V(t+T) = \lambda V(t) \]
  \end{theorem}

  \reference{406}

  \begin{theorem}[Massera]
    Si l'équation $Y' = A(t) Y + B(t)$ (où $A$ et $B$ sont $T$-périodiques) admet une solution bornée sur $\mathbb{R}$, alors elle admet une solution $T$-périodique.
  \end{theorem}

  \subsection{Applications}

  \subsubsection{Résolution d'équations différentielles non linéaires}

  \reference{391}

  \begin{application}[Équations de Bernoulli]
    Soit $(B) : y' = a(t) y + b(t) y^\alpha$ (où $\alpha \in \mathbb{R} \setminus \{0,1\}$). On pose $z=y^{1-\alpha}$ et on a
    \[ (B) \iff \frac{1}{1-\alpha} z' = a(t)z + b(t) \]
  \end{application}

  \begin{corollary}[Équations de Ricatti]
    Soit $(R) : y' = a(t) y^2 + b(t) y + c(t)$ qui admet pour solution particulière $\varphi_0$. On pose $y = \varphi_0 + z$ et on a
    \[ (R) \iff (2a(t) \varphi_0(t) + b(t))z + a(t)z^2 \]
    qui est une équation de Bernoulli.
  \end{corollary}

  \begin{example}
    Les solutions maximales de l'équation $y' + y + y^2 + 1 = 0$ sont de la forme $t \mapsto e^{\frac{2i\pi}{3}} + \frac{\sqrt{3}}{e^{i (\sqrt{3}t+\theta)} + i}$, définies que des intervalles ouverts de longueur $\frac{2 \pi}{\sqrt{3}}$.
  \end{example}

  \subsubsection{Stabilité}

  \reference[I-P]{302}

  \begin{application}[Théorème de stabilité de Liapounov]
    Soit $f \in \mathcal{C}^1(\mathbb{R}^n)$ telle que $f(0) = 0$. On considère le problème de Cauchy
    \[ \begin{cases} y'=f(y) \\ y(0) = y_0 \end{cases} \]
    Si toute valeur propre complexe de $\mathrm{d}f_0$ est de partie réelle strictement négative, alors $\forall y_0$ suffisamment proche de $0$, la solution maximale $y(t)$ est bien définie et converge vers $0$ en $+ \infty$ à une vitesse exponentielle.
  \end{application}

  \subsubsection{Étude d'équations fonctionnelles et matricielles}

  \reference[GOU20]{384}

  \begin{application}
    L'ensemble des fonctions $f : \mathbb{R}^+_* \rightarrow \mathbb{R}$ vérifiant $\forall t > 0, \, f'(t) = f \left( \frac{1}{t} \right)$ est l'ensemble des solutions de l'équation différentielle linéaire homogène $t^2 y'' + y = 0$.
  \end{application}

  \reference[I-P]{177}

  \begin{lemma}
    Soit $\Vert . \Vert$ une norme d'algèbre sur $\mathcal{M}_n(\mathbb{C})$, et soit $A \in \mathcal{M}_n(\mathbb{C})$ une matrice dont les valeurs propres sont de partie réelle strictement négative. Alors il existe une fonction polynômiale $P : \mathbb{R} \rightarrow \mathbb{R}$ et $\lambda > 0$ tels que $\Vert e^{tA} \Vert \leq e^{- \lambda t} P(t)$.
  \end{lemma}

  \dev{equation-de-sylvester}

  \begin{application}[Équation de Sylvester]
    Soient $A$ et $B \in \mathcal{M}_n(\mathbb{C})$ deux matrices dont les valeurs propres sont de partie réelle strictement négative. Alors pour tout $C \in \mathcal{M}_n(\mathbb{C})$, l'équation $AX + XB = C$ admet une unique solution $X$ dans $\mathcal{M}_n(\mathbb{C})$.
  \end{application}
  %</content>
\end{document}
